#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
GCæ—¥å¿—åˆ†æMCPæœåŠ¡å™¨
æä¾›æ ‡å‡†åŒ–çš„MCPæ¥å£ç”¨äºGCæ—¥å¿—åˆ†æåŠŸèƒ½
"""

import asyncio
import json
import logging
import os
import sys
from typing import Any, Dict, List, Optional

# å¯¼å…¥MCPåº“
from mcp.server import Server
from mcp.server.stdio import stdio_server
from mcp.types import (
    CallToolRequest,
    CallToolResult,
    ListToolsRequest,
    TextContent,
    Tool,
    EmbeddedResource,
)

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_root = os.path.dirname(os.path.abspath(__file__))
sys.path.insert(0, project_root)

# å¯¼å…¥æˆ‘ä»¬çš„GCåˆ†ææ¨¡å—
from parser.g1_parser import parse_gc_log as parse_g1_log
from parser.ibm_parser import parse_gc_log as parse_j9_log
from utils.log_loader import LogLoader, GCLogType
from analyzer.metrics import analyze_gc_metrics, GCMetricsAnalyzer
from analyzer.report_generator import generate_gc_report
from rules.alert_engine import GCAlertEngine

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# åˆ›å»ºMCPæœåŠ¡å™¨å®ä¾‹
app = Server("gc-log-analyzer")

# å…¨å±€çŠ¶æ€
current_analysis_result = None
metrics_analyzer = GCMetricsAnalyzer()
alert_engine = GCAlertEngine()


@app.list_tools()
async def list_tools() -> List[Tool]:
    """
    è¿”å›å¯ç”¨çš„å·¥å…·åˆ—è¡¨
    """
    return [
        Tool(
            name="analyze_gc_log",
            description="åˆ†æGCæ—¥å¿—æ–‡ä»¶ï¼Œæ”¯æŒG1å’ŒIBM J9VMæ ¼å¼",
            inputSchema={
                "type": "object",
                "properties": {
                    "file_path": {
                        "type": "string",
                        "description": "GCæ—¥å¿—æ–‡ä»¶çš„è·¯å¾„"
                    },
                    "analysis_type": {
                        "type": "string",
                        "enum": ["basic", "detailed"],
                        "description": "åˆ†æç±»å‹ï¼šbasic(åŸºç¡€ç»Ÿè®¡) æˆ– detailed(è¯¦ç»†æŒ‡æ ‡)",
                        "default": "detailed"
                    }
                },
                "required": ["file_path"]
            }
        ),
        Tool(
            name="get_gc_metrics",
            description="è·å–ä¸Šæ¬¡åˆ†æçš„è¯¦ç»†æ€§èƒ½æŒ‡æ ‡",
            inputSchema={
                "type": "object",
                "properties": {
                    "metric_types": {
                        "type": "array",
                        "items": {
                            "type": "string",
                            "enum": [
                                "throughput", "latency", "frequency", 
                                "memory", "trends", "health", "all"
                            ]
                        },
                        "description": "è¦è·å–çš„æŒ‡æ ‡ç±»å‹",
                        "default": ["all"]
                    }
                }
            }
        ),
        Tool(
            name="compare_gc_logs",
            description="æ¯”è¾ƒä¸¤ä¸ªGCæ—¥å¿—æ–‡ä»¶çš„æ€§èƒ½å·®å¼‚",
            inputSchema={
                "type": "object",
                "properties": {
                    "file_path_1": {
                        "type": "string",
                        "description": "ç¬¬ä¸€ä¸ªGCæ—¥å¿—æ–‡ä»¶è·¯å¾„"
                    },
                    "file_path_2": {
                        "type": "string",
                        "description": "ç¬¬äºŒä¸ªGCæ—¥å¿—æ–‡ä»¶è·¯å¾„"
                    }
                },
                "required": ["file_path_1", "file_path_2"]
            }
        ),
        Tool(
            name="detect_gc_issues",
            description="æ£€æµ‹GCæ€§èƒ½é—®é¢˜å’Œç»™å‡ºä¼˜åŒ–å»ºè®®",
            inputSchema={
                "type": "object",
                "properties": {
                    "threshold_config": {
                        "type": "object",
                        "description": "è‡ªå®šä¹‰é˜ˆå€¼é…ç½®ï¼ˆå¯é€‰ï¼‰",
                        "properties": {
                            "max_pause_time": {"type": "number", "default": 100},
                            "min_throughput": {"type": "number", "default": 95}
                        }
                    }
                }
            }
        ),
        Tool(
            name="generate_gc_report",
            description="ç”Ÿæˆä¸“ä¸šçš„GCæ€§èƒ½åˆ†ææŠ¥å‘Šï¼ˆHTMLæˆ–Markdownæ ¼å¼ï¼‰",
            inputSchema={
                "type": "object",
                "properties": {
                    "format_type": {
                        "type": "string",
                        "enum": ["markdown", "html"],
                        "description": "æŠ¥å‘Šæ ¼å¼ï¼šmarkdown æˆ– html",
                        "default": "markdown"
                    },
                    "output_file": {
                        "type": "string",
                        "description": "è¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼‰"
                    },
                    "include_alerts": {
                        "type": "boolean",
                        "description": "æ˜¯å¦åŒ…å«æ€§èƒ½è­¦æŠ¥ä¿¡æ¯",
                        "default": "true"
                    }
                }
            }
        )
    ]


@app.call_tool()
async def call_tool(name: str, arguments: Dict[str, Any]) -> CallToolResult:
    """
    å¤„ç†å·¥å…·è°ƒç”¨è¯·æ±‚
    """
    try:
        if name == "analyze_gc_log":
            return await analyze_gc_log_tool(arguments)
        elif name == "get_gc_metrics":
            return await get_gc_metrics_tool(arguments)
        elif name == "compare_gc_logs":
            return await compare_gc_logs_tool(arguments)
        elif name == "detect_gc_issues":
            return await detect_gc_issues_tool(arguments)
        elif name == "generate_gc_report":
            return await generate_gc_report_tool(arguments)
        else:
            raise ValueError(f"æœªçŸ¥å·¥å…·: {name}")
    
    except Exception as e:
        logger.error(f"å·¥å…·è°ƒç”¨é”™è¯¯ {name}: {e}")
        return CallToolResult(
            content=[
                TextContent(
                    type="text",
                    text=f"âŒ é”™è¯¯: {str(e)}"
                )
            ]
        )


async def analyze_gc_log_tool(arguments: Dict[str, Any]) -> CallToolResult:
    """
    åˆ†æGCæ—¥å¿—æ–‡ä»¶å·¥å…·
    """
    global current_analysis_result
    
    try:
        # å‚æ•°éªŒè¯
        file_path = arguments.get("file_path")
        analysis_type = arguments.get("analysis_type", "detailed")
        
        if not file_path:
            raise ValueError("ç¼ºå°‘å¿…éœ€å‚æ•° file_path")
        
        if not isinstance(file_path, str):
            raise ValueError(f"file_path å¿…é¡»æ˜¯å­—ç¬¦ä¸²ï¼Œå½“å‰ç±»å‹: {type(file_path).__name__}")
        
        if analysis_type not in ["basic", "detailed"]:
            raise ValueError(f"analysis_type å¿…é¡»æ˜¯ 'basic' æˆ– 'detailed'ï¼Œå½“å‰å€¼: {analysis_type}")
        
        # æ–‡ä»¶å­˜åœ¨æ€§æ£€æŸ¥
        if not os.path.exists(file_path):
            raise FileNotFoundError(f"æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
        
        # æ–‡ä»¶å¯è¯»æ€§æ£€æŸ¥
        if not os.access(file_path, os.R_OK):
            raise PermissionError(f"æ–‡ä»¶ä¸å¯è¯»: {file_path}")
        
        # æ–‡ä»¶å¤§å°æ£€æŸ¥ï¼ˆé™åˆ¶ä¸º100MBï¼‰
        file_size = os.path.getsize(file_path)
        max_size = 100 * 1024 * 1024  # 100MB
        if file_size > max_size:
            raise ValueError(f"æ–‡ä»¶è¿‡å¤§: {file_size / (1024*1024):.1f}MBï¼Œæœ€å¤§æ”¯æŒ: {max_size / (1024*1024):.1f}MB")
        
        # åŠ è½½æ—¥å¿—æ–‡ä»¶
        try:
            loader = LogLoader()
            log_content, log_type = loader.load_log_file(file_path)
        except Exception as e:
            raise ValueError(f"æ—¥å¿—æ–‡ä»¶åŠ è½½å¤±è´¥: {str(e)}")
        
        # æ ¹æ®æ—¥å¿—ç±»å‹é€‰æ‹©è§£æå™¨
        try:
            if log_type == GCLogType.G1:
                parse_result = parse_g1_log(log_content)
                parser_type = "G1 GC"
            elif log_type == GCLogType.IBM_J9:
                parse_result = parse_j9_log(log_content)
                parser_type = "IBM J9VM"
            else:
                raise ValueError(f"ä¸æ”¯æŒçš„æ—¥å¿—æ ¼å¼: {log_type}")
        except Exception as e:
            raise ValueError(f"æ—¥å¿—è§£æå¤±è´¥: {str(e)}")
        
        # éªŒè¯è§£æç»“æœ
        if not parse_result or not isinstance(parse_result, dict):
            raise ValueError("æ—¥å¿—è§£æç»“æœæ— æ•ˆ")
        
        # åˆ†ææ€§èƒ½æŒ‡æ ‡
        events = parse_result.get('events', [])
        if not events:
            logger.warning(f"æ—¥å¿—æ–‡ä»¶ä¸­æœªæ‰¾åˆ°GCäº‹ä»¶: {file_path}")
            metrics = None
        else:
            try:
                metrics = analyze_gc_metrics(events)
            except Exception as e:
                logger.error(f"æŒ‡æ ‡åˆ†æå¤±è´¥: {e}")
                metrics = None
        
        # ä¿å­˜åˆ†æç»“æœåˆ°å…¨å±€çŠ¶æ€
        current_analysis_result = {
            'file_path': file_path,
            'log_type': log_type.value,
            'parser_type': parser_type,
            'parse_result': parse_result,
            'metrics': metrics,
            'events_count': len(events)
        }
        
        # ç”Ÿæˆåˆ†ææŠ¥å‘Š
        try:
            if analysis_type == "basic":
                report = generate_basic_report(parse_result, metrics, parser_type)
            else:
                report = generate_detailed_report(parse_result, metrics, parser_type)
        except Exception as e:
            raise ValueError(f"æŠ¥å‘Šç”Ÿæˆå¤±è´¥: {str(e)}")
        
        return CallToolResult(
            content=[
                TextContent(
                    type="text", 
                    text=report
                )
            ]
        )
        
    except Exception as e:
        logger.error(f"analyze_gc_log_tool æ‰§è¡Œå¤±è´¥: {e}")
        return CallToolResult(
            content=[
                TextContent(
                    type="text",
                    text=f"âŒ åˆ†æå¤±è´¥: {str(e)}"
                )
            ]
        )


async def get_gc_metrics_tool(arguments: Dict[str, Any]) -> CallToolResult:
    """
    è·å–GCæŒ‡æ ‡å·¥å…·
    """
    global current_analysis_result
    
    try:
        # æ£€æŸ¥æ˜¯å¦æœ‰åˆ†æç»“æœ
        if not current_analysis_result:
            return CallToolResult(
                content=[
                    TextContent(
                        type="text",
                        text="âŒ è¯·å…ˆä½¿ç”¨ analyze_gc_log å·¥å…·åˆ†æä¸€ä¸ªæ—¥å¿—æ–‡ä»¶"
                    )
                ]
            )
        
        # å‚æ•°éªŒè¯
        metric_types = arguments.get("metric_types", ["all"])
        if not isinstance(metric_types, list):
            metric_types = [metric_types] if isinstance(metric_types, str) else ["all"]
        
        # éªŒè¯æŒ‡æ ‡ç±»å‹
        valid_types = ["all", "throughput", "latency", "frequency", "memory", "trends", "health"]
        invalid_types = [t for t in metric_types if t not in valid_types]
        if invalid_types:
            return CallToolResult(
                content=[
                    TextContent(
                        type="text",
                        text=f"âŒ æ— æ•ˆçš„æŒ‡æ ‡ç±»å‹: {invalid_types}\næ”¯æŒçš„ç±»å‹: {valid_types}"
                    )
                ]
            )
        
        # è·å–æŒ‡æ ‡æ•°æ®
        metrics = current_analysis_result.get('metrics')
        if not metrics:
            return CallToolResult(
                content=[
                    TextContent(
                        type="text",
                        text="âŒ æ²¡æœ‰å¯ç”¨çš„æŒ‡æ ‡æ•°æ®ï¼Œè¯·æ£€æŸ¥æ—¥å¿—æ–‡ä»¶æ˜¯å¦åŒ…å«GCäº‹ä»¶"
                    )
                ]
            )
        
        # ç”ŸæˆæŒ‡æ ‡æŠ¥å‘Š
        try:
            report = generate_metrics_report(metrics, metric_types)
        except Exception as e:
            logger.error(f"æŒ‡æ ‡æŠ¥å‘Šç”Ÿæˆå¤±è´¥: {e}")
            return CallToolResult(
                content=[
                    TextContent(
                        type="text",
                        text=f"âŒ æŒ‡æ ‡æŠ¥å‘Šç”Ÿæˆå¤±è´¥: {str(e)}"
                    )
                ]
            )
        
        return CallToolResult(
            content=[
                TextContent(
                    type="text",
                    text=report
                )
            ]
        )
        
    except Exception as e:
        logger.error(f"get_gc_metrics_tool æ‰§è¡Œå¤±è´¥: {e}")
        return CallToolResult(
            content=[
                TextContent(
                    type="text",
                    text=f"âŒ è·å–æŒ‡æ ‡å¤±è´¥: {str(e)}"
                )
            ]
        )


async def compare_gc_logs_tool(arguments: Dict[str, Any]) -> CallToolResult:
    """
    æ¯”è¾ƒGCæ—¥å¿—å·¥å…·
    """
    try:
        # å‚æ•°éªŒè¯
        file_path_1 = arguments.get("file_path_1")
        file_path_2 = arguments.get("file_path_2")
        
        if not file_path_1 or not file_path_2:
            return CallToolResult(
                content=[
                    TextContent(
                        type="text",
                        text="âŒ ç¼ºå°‘å¿…éœ€å‚æ•°: file_path_1 å’Œ file_path_2"
                    )
                ]
            )
        
        if not isinstance(file_path_1, str) or not isinstance(file_path_2, str):
            return CallToolResult(
                content=[
                    TextContent(
                        type="text",
                        text="âŒ æ–‡ä»¶è·¯å¾„å¿…é¡»æ˜¯å­—ç¬¦ä¸²"
                    )
                ]
            )
        
        if file_path_1 == file_path_2:
            return CallToolResult(
                content=[
                    TextContent(
                        type="text",
                        text="âŒ ä¸èƒ½æ¯”è¾ƒç›¸åŒçš„æ–‡ä»¶"
                    )
                ]
            )
        
        # åˆ†æä¸¤ä¸ªæ–‡ä»¶
        results = []
        for i, file_path in enumerate([file_path_1, file_path_2], 1):
            try:
                # æ–‡ä»¶æ£€æŸ¥
                if not os.path.exists(file_path):
                    return CallToolResult(
                        content=[
                            TextContent(
                                type="text",
                                text=f"âŒ æ–‡ä»¶{i}ä¸å­˜åœ¨: {file_path}"
                            )
                        ]
                    )
                
                if not os.access(file_path, os.R_OK):
                    return CallToolResult(
                        content=[
                            TextContent(
                                type="text",
                                text=f"âŒ æ–‡ä»¶{i}ä¸å¯è¯»: {file_path}"
                            )
                        ]
                    )
                
                # åŠ è½½å’Œè§£ææ–‡ä»¶
                loader = LogLoader()
                log_content, log_type = loader.load_log_file(file_path)
                
                if log_type == GCLogType.G1:
                    parse_result = parse_g1_log(log_content)
                elif log_type == GCLogType.IBM_J9:
                    parse_result = parse_j9_log(log_content)
                else:
                    return CallToolResult(
                        content=[
                            TextContent(
                                type="text",
                                text=f"âŒ æ–‡ä»¶{i}ä¸æ”¯æŒçš„æ—¥å¿—æ ¼å¼: {log_type}"
                            )
                        ]
                    )
                
                events = parse_result.get('events', [])
                if not events:
                    logger.warning(f"æ–‡ä»¶{i}ä¸­æœªæ‰¾åˆ°GCäº‹ä»¶: {file_path}")
                    metrics = None
                else:
                    metrics = analyze_gc_metrics(events)
                
                results.append({
                    'file_path': file_path,
                    'log_type': log_type.value,
                    'metrics': metrics,
                    'events_count': len(events)
                })
                
            except Exception as e:
                logger.error(f"å¤„ç†æ–‡ä»¶{i}å¤±è´¥: {e}")
                return CallToolResult(
                    content=[
                        TextContent(
                            type="text",
                            text=f"âŒ å¤„ç†æ–‡ä»¶{i}å¤±è´¥: {str(e)}"
                        )
                    ]
                )
        
        # æ£€æŸ¥æ˜¯å¦æœ‰æœ‰æ•ˆçš„æŒ‡æ ‡æ•°æ®
        if not results[0]['metrics'] or not results[1]['metrics']:
            missing_files = []
            if not results[0]['metrics']:
                missing_files.append("æ–‡ä»¶1")
            if not results[1]['metrics']:
                missing_files.append("æ–‡ä»¶2")
            
            return CallToolResult(
                content=[
                    TextContent(
                        type="text",
                        text=f"âŒ {', '.join(missing_files)}ç¼ºå°‘æœ‰æ•ˆçš„GCæ•°æ®ï¼Œæ— æ³•è¿›è¡Œæ¯”è¾ƒ"
                    )
                ]
            )
        
        # ç”Ÿæˆæ¯”è¾ƒæŠ¥å‘Š
        try:
            report = generate_comparison_report(results[0], results[1])
        except Exception as e:
            logger.error(f"æ¯”è¾ƒæŠ¥å‘Šç”Ÿæˆå¤±è´¥: {e}")
            return CallToolResult(
                content=[
                    TextContent(
                        type="text",
                        text=f"âŒ æ¯”è¾ƒæŠ¥å‘Šç”Ÿæˆå¤±è´¥: {str(e)}"
                    )
                ]
            )
        
        return CallToolResult(
            content=[
                TextContent(
                    type="text",
                    text=report
                )
            ]
        )
        
    except Exception as e:
        logger.error(f"compare_gc_logs_tool æ‰§è¡Œå¤±è´¥: {e}")
        return CallToolResult(
            content=[
                TextContent(
                    type="text",
                    text=f"âŒ æ¯”è¾ƒå¤±è´¥: {str(e)}"
                )
            ]
        )


async def detect_gc_issues_tool(arguments: Dict[str, Any]) -> CallToolResult:
    """
    æ£€æµ‹GCé—®é¢˜å·¥å…·
    """
    global current_analysis_result
    
    try:
        # æ£€æŸ¥æ˜¯å¦æœ‰åˆ†æç»“æœ
        if not current_analysis_result:
            return CallToolResult(
                content=[
                    TextContent(
                        type="text",
                        text="âŒ è¯·å…ˆä½¿ç”¨ analyze_gc_log å·¥å…·åˆ†æä¸€ä¸ªæ—¥å¿—æ–‡ä»¶"
                    )
                ]
            )
        
        # å‚æ•°éªŒè¯
        threshold_config = arguments.get("threshold_config", {})
        if not isinstance(threshold_config, dict):
            return CallToolResult(
                content=[
                    TextContent(
                        type="text",
                        text="âŒ threshold_config å¿…é¡»æ˜¯å­—å…¸ç±»å‹"
                    )
                ]
            )
        
        # éªŒè¯é˜ˆå€¼å‚æ•°
        if "max_pause_time" in threshold_config:
            max_pause_time = threshold_config["max_pause_time"]
            if not isinstance(max_pause_time, (int, float)) or max_pause_time <= 0:
                return CallToolResult(
                    content=[
                        TextContent(
                            type="text",
                            text="âŒ max_pause_time å¿…é¡»æ˜¯æ­£æ•°"
                        )
                    ]
                )
        
        if "min_throughput" in threshold_config:
            min_throughput = threshold_config["min_throughput"]
            if not isinstance(min_throughput, (int, float)) or not (0 <= min_throughput <= 100):
                return CallToolResult(
                    content=[
                        TextContent(
                            type="text",
                            text="âŒ min_throughput å¿…é¡»æ˜¯ 0-100 ä¹‹é—´çš„æ•°å€¼"
                        )
                    ]
                )
        
        # è·å–æŒ‡æ ‡æ•°æ®
        metrics = current_analysis_result.get('metrics')
        if not metrics:
            return CallToolResult(
                content=[
                    TextContent(
                        type="text",
                        text="âŒ æ²¡æœ‰å¯ç”¨çš„æŒ‡æ ‡æ•°æ®ï¼Œè¯·æ£€æŸ¥æ—¥å¿—æ–‡ä»¶æ˜¯å¦åŒ…å«GCäº‹ä»¶"
                    )
                ]
            )
        
        # ç”Ÿæˆé—®é¢˜æ£€æµ‹æŠ¥å‘Š
        try:
            report = generate_issues_report(metrics, threshold_config)
        except Exception as e:
            logger.error(f"é—®é¢˜æ£€æµ‹æŠ¥å‘Šç”Ÿæˆå¤±è´¥: {e}")
            return CallToolResult(
                content=[
                    TextContent(
                        type="text",
                        text=f"âŒ é—®é¢˜æ£€æµ‹å¤±è´¥: {str(e)}"
                    )
                ]
            )
        
        return CallToolResult(
            content=[
                TextContent(
                    type="text",
                    text=report
                )
            ]
        )
        
    except Exception as e:
        logger.error(f"detect_gc_issues_tool æ‰§è¡Œå¤±è´¥: {e}")
        return CallToolResult(
            content=[
                TextContent(
                    type="text",
                    text=f"âŒ æ£€æµ‹å¤±è´¥: {str(e)}"
                )
            ]
        )


async def generate_gc_report_tool(arguments: Dict[str, Any]) -> CallToolResult:
    """
    ç”ŸæˆGCåˆ†ææŠ¥å‘Šå·¥å…·
    """
    global current_analysis_result, alert_engine
    
    try:
        # æ£€æŸ¥æ˜¯å¦æœ‰åˆ†æç»“æœ
        if not current_analysis_result:
            return CallToolResult(
                content=[
                    TextContent(
                        type="text",
                        text="âŒ è¯·å…ˆä½¿ç”¨ analyze_gc_log å·¥å…·åˆ†æä¸€ä¸ªæ—¥å¿—æ–‡ä»¶"
                    )
                ]
            )
        
        # å‚æ•°éªŒè¯
        format_type = arguments.get("format_type", "markdown")
        output_file = arguments.get("output_file")
        include_alerts = arguments.get("include_alerts", True)
        
        if format_type not in ["markdown", "html"]:
            return CallToolResult(
                content=[
                    TextContent(
                        type="text",
                        text="âŒ format_type å¿…é¡»æ˜¯ 'markdown' æˆ– 'html'"
                    )
                ]
            )
        
        if output_file and not isinstance(output_file, str):
            return CallToolResult(
                content=[
                    TextContent(
                        type="text",
                        text="âŒ output_file å¿…é¡»æ˜¯å­—ç¬¦ä¸²ç±»å‹"
                    )
                ]
            )
        
        if not isinstance(include_alerts, bool):
            include_alerts = bool(include_alerts)
        
        # æ£„å–æ•°æ®
        metrics = current_analysis_result.get('metrics')
        parse_result = current_analysis_result.get('parse_result', {})
        
        if not metrics:
            return CallToolResult(
                content=[
                    TextContent(
                        type="text",
                        text="âŒ æ²¡æœ‰å¯ç”¨çš„æŒ‡æ ‡æ•°æ®ï¼Œè¯·æ£€æŸ¥æ—¥å¿—æ–‡ä»¶æ˜¯å¦åŒ…å«GCäº‹ä»¶"
                    )
                ]
            )
        
        # å‡†å¤‡åˆ†ææ•°æ®
        analysis_data = {
            'gc_type': current_analysis_result.get('parser_type', 'Unknown'),
            'file_path': current_analysis_result.get('file_path', 'Unknown'),
            'total_events': current_analysis_result.get('events_count', 0)
        }
        
        # è½¬æ¢æŒ‡æ ‡æ•°æ®ä¸ºå­—å…¸æ ¼å¼
        try:
            metrics_data = {
                'throughput': {
                    'app_time_percentage': metrics.throughput_percentage,
                    'gc_time_percentage': metrics.gc_overhead_percentage
                },
                'latency': {
                    'avg_pause_time': metrics.avg_pause_time,
                    'max_pause_time': metrics.max_pause_time,
                    'p50_pause_time': metrics.p50_pause_time,
                    'p95_pause_time': metrics.p95_pause_time,
                    'p99_pause_time': metrics.p99_pause_time,
                    'min_pause_time': metrics.min_pause_time
                },
                'frequency': {
                    'gc_frequency': metrics.gc_frequency,
                    'young_gc_frequency': metrics.young_gc_frequency,
                    'full_gc_frequency': metrics.full_gc_frequency
                },
                'memory': {
                    'avg_heap_utilization': metrics.avg_heap_utilization,
                    'max_heap_utilization': metrics.max_heap_utilization,
                    'memory_allocation_rate': metrics.memory_allocation_rate,
                    'memory_reclaim_efficiency': metrics.memory_reclaim_efficiency
                }
            }
        except AttributeError as e:
            logger.error(f"æŒ‡æ ‡æ•°æ®è½¬æ¢å¤±è´¥: {e}")
            return CallToolResult(
                content=[
                    TextContent(
                        type="text",
                        text=f"âŒ æŒ‡æ ‡æ•°æ®æ ¼å¼é”™è¯¯: {str(e)}"
                    )
                ]
            )
        
        # ç”Ÿæˆè­¦æŠ¥ï¼ˆå¦‚æœéœ€è¦ï¼‰
        alerts_data = None
        if include_alerts:
            try:
                # ä½¿ç”¨è­¦æŠ¥å¼•æ“åˆ†ææŒ‡æ ‡
                if metrics:
                    alerts = alert_engine.evaluate_metrics(metrics)
                    alerts_data = [{
                        'severity': alert.severity.value,
                        'category': alert.category.value,
                        'message': alert.message,
                        'details': alert.recommendation,
                        'threshold': alert.threshold
                    } for alert in alerts]
            except Exception as e:
                logger.warning(f"è­¦æŠ¥ç”Ÿæˆå¤±è´¥ï¼Œå°†è·³è¿‡: {e}")
                alerts_data = None
        
        # æ£€æŸ¥è¾“å‡ºæ–‡ä»¶ç›®å½•æ˜¯å¦å¯å†™
        if output_file:
            output_dir = os.path.dirname(output_file)
            if output_dir and not os.path.exists(output_dir):
                try:
                    os.makedirs(output_dir, exist_ok=True)
                except OSError as e:
                    return CallToolResult(
                        content=[
                            TextContent(
                                type="text",
                                text=f"âŒ æ— æ³•åˆ›å»ºè¾“å‡ºç›®å½•: {str(e)}"
                            )
                        ]
                    )
            
            if output_dir and not os.access(output_dir, os.W_OK):
                return CallToolResult(
                    content=[
                        TextContent(
                            type="text",
                            text=f"âŒ è¾“å‡ºç›®å½•ä¸å¯å†™: {output_dir}"
                        )
                    ]
                )
        
        # ç”ŸæˆæŠ¥å‘Š
        try:
            report_content = generate_gc_report(
                analysis_data=analysis_data,
                metrics_data=metrics_data,
                alerts_data=alerts_data,
                format_type=format_type,
                output_file=output_file
            )
            
            result_text = f"âœ… {format_type.upper()}æ ¼å¼çš„GCåˆ†ææŠ¥å‘Šå·²ç”Ÿæˆ\n\n"
            
            if output_file:
                result_text += f"ğŸ“ æŠ¥å‘Šå·²ä¿å­˜åˆ°: {output_file}\n\n"
            
            # å¦‚æœæ˜¯Markdownæ ¼å¼ï¼Œç›´æ¥æ˜¾ç¤ºå†…å®¹
            if format_type.lower() == "markdown":
                # é™åˆ¶æ˜¾ç¤ºé•¿åº¦ä»¥é¿å…è¾“å‡ºè¿‡é•¿
                max_display_length = 3000
                if len(report_content) > max_display_length:
                    result_text += f"ğŸ“‹ æŠ¥å‘Šå†…å®¹é¢„è§ˆï¼ˆå‰{max_display_length}ä¸ªå­—ç¬¦ï¼‰:\n\n" + report_content[:max_display_length] + "\n\n...å†…å®¹è¿‡é•¿ï¼Œå·²æˆªæ–­"
                else:
                    result_text += "ğŸ“‹ æŠ¥å‘Šå†…å®¹:\n\n" + report_content
            else:
                result_text += "ğŸŒ HTMLæŠ¥å‘Šå·²ç”Ÿæˆï¼Œè¯·æŸ¥çœ‹è¾“å‡ºæ–‡ä»¶"
            
            return CallToolResult(
                content=[
                    TextContent(
                        type="text",
                        text=result_text
                    )
                ]
            )
            
        except Exception as e:
            logger.error(f"æŠ¥å‘Šç”Ÿæˆå¤±è´¥: {e}")
            return CallToolResult(
                content=[
                    TextContent(
                        type="text",
                        text=f"âŒ ç”ŸæˆæŠ¥å‘Šå¤±è´¥: {str(e)}"
                    )
                ]
            )
            
    except Exception as e:
        logger.error(f"generate_gc_report_tool æ‰§è¡Œå¤±è´¥: {e}")
        return CallToolResult(
            content=[
                TextContent(
                    type="text",
                    text=f"âŒ æŠ¥å‘Šç”Ÿæˆå¤±è´¥: {str(e)}"
                )
            ]
        )


def generate_basic_report(parse_result: Dict, metrics: Any, parser_type: str) -> str:
    """ç”ŸæˆåŸºç¡€åˆ†ææŠ¥å‘Š"""
    gc_count = parse_result.get('gc_count', {})
    
    report = f"""
## ğŸ“Š GCæ—¥å¿—åŸºç¡€åˆ†ææŠ¥å‘Š

### æ—¥å¿—ä¿¡æ¯
- **è§£æå™¨ç±»å‹**: {parser_type}
- **æ€»GCæ¬¡æ•°**: {gc_count.get('total', 0)}

### GCç»Ÿè®¡
"""
    
    for gc_type, count in gc_count.items():
        if gc_type != 'total' and count > 0:
            report += f"- **{gc_type.title()} GC**: {count}æ¬¡\n"
    
    if metrics:
        report += f"""
### å…³é”®æŒ‡æ ‡
- **æ€§èƒ½è¯„åˆ†**: {metrics.performance_score:.1f}/100
- **å¥åº·çŠ¶æ€**: {metrics.health_status}
- **ååé‡**: {metrics.throughput_percentage:.1f}%
- **å¹³å‡åœé¡¿**: {metrics.avg_pause_time:.1f}ms
- **æœ€å¤§åœé¡¿**: {metrics.max_pause_time:.1f}ms
"""
    
    return report.strip()


def generate_detailed_report(parse_result: Dict, metrics: Any, parser_type: str) -> str:
    """ç”Ÿæˆè¯¦ç»†åˆ†ææŠ¥å‘Š"""
    basic_report = generate_basic_report(parse_result, metrics, parser_type)
    
    if not metrics:
        return basic_report
    
    detailed_section = f"""

### ğŸ“ˆ è¯¦ç»†æ€§èƒ½æŒ‡æ ‡

#### ååé‡æŒ‡æ ‡
- **åº”ç”¨ååé‡**: {metrics.throughput_percentage:.2f}%
- **GCå¼€é”€**: {metrics.gc_overhead_percentage:.2f}%

#### å»¶è¿ŸæŒ‡æ ‡
- **å¹³å‡åœé¡¿**: {metrics.avg_pause_time:.1f}ms
- **P50åœé¡¿**: {metrics.p50_pause_time:.1f}ms
- **P95åœé¡¿**: {metrics.p95_pause_time:.1f}ms
- **P99åœé¡¿**: {metrics.p99_pause_time:.1f}ms
- **æœ€å¤§åœé¡¿**: {metrics.max_pause_time:.1f}ms
- **æœ€å°åœé¡¿**: {metrics.min_pause_time:.1f}ms

#### é¢‘ç‡æŒ‡æ ‡
- **æ€»GCé¢‘ç‡**: {metrics.gc_frequency:.2f} æ¬¡/ç§’
- **Young GCé¢‘ç‡**: {metrics.young_gc_frequency:.2f} æ¬¡/ç§’
- **Full GCé¢‘ç‡**: {metrics.full_gc_frequency:.2f} æ¬¡/ç§’

#### å†…å­˜æŒ‡æ ‡
- **å¹³å‡å †åˆ©ç”¨ç‡**: {metrics.avg_heap_utilization:.1f}%
- **æœ€å¤§å †åˆ©ç”¨ç‡**: {metrics.max_heap_utilization:.1f}%
- **å†…å­˜åˆ†é…ç‡**: {metrics.memory_allocation_rate:.1f}MB/äº‹ä»¶
- **å†…å­˜å›æ”¶æ•ˆç‡**: {metrics.memory_reclaim_efficiency:.1f}%

#### è¶‹åŠ¿åˆ†æ
- **åœé¡¿æ—¶é—´è¶‹åŠ¿**: {metrics.pause_time_trend}
- **å†…å­˜ä½¿ç”¨è¶‹åŠ¿**: {metrics.memory_usage_trend}

### ğŸ¯ æ€§èƒ½è¯„ä¼°
- **ç»¼åˆè¯„åˆ†**: {metrics.performance_score:.1f}/100
- **å¥åº·çŠ¶æ€**: {metrics.health_status}
"""
    
    return basic_report + detailed_section


def generate_metrics_report(metrics: Any, metric_types: List[str]) -> str:
    """ç”ŸæˆæŒ‡æ ‡æŠ¥å‘Š"""
    report = "## ğŸ“Š GCæ€§èƒ½æŒ‡æ ‡è¯¦æƒ…\n\n"
    
    if "all" in metric_types or "throughput" in metric_types:
        report += f"""### ğŸš€ ååé‡æŒ‡æ ‡
- åº”ç”¨ååé‡: {metrics.throughput_percentage:.2f}%
- GCå¼€é”€: {metrics.gc_overhead_percentage:.2f}%

"""
    
    if "all" in metric_types or "latency" in metric_types:
        report += f"""### â±ï¸ å»¶è¿ŸæŒ‡æ ‡
- å¹³å‡åœé¡¿: {metrics.avg_pause_time:.1f}ms
- P50åœé¡¿: {metrics.p50_pause_time:.1f}ms
- P95åœé¡¿: {metrics.p95_pause_time:.1f}ms
- P99åœé¡¿: {metrics.p99_pause_time:.1f}ms
- æœ€å¤§åœé¡¿: {metrics.max_pause_time:.1f}ms

"""
    
    if "all" in metric_types or "frequency" in metric_types:
        report += f"""### ğŸ“Š é¢‘ç‡æŒ‡æ ‡
- æ€»GCé¢‘ç‡: {metrics.gc_frequency:.2f} æ¬¡/ç§’
- Young GCé¢‘ç‡: {metrics.young_gc_frequency:.2f} æ¬¡/ç§’
- Full GCé¢‘ç‡: {metrics.full_gc_frequency:.2f} æ¬¡/ç§’

"""
    
    if "all" in metric_types or "memory" in metric_types:
        report += f"""### ğŸ’¾ å†…å­˜æŒ‡æ ‡
- å¹³å‡å †åˆ©ç”¨ç‡: {metrics.avg_heap_utilization:.1f}%
- æœ€å¤§å †åˆ©ç”¨ç‡: {metrics.max_heap_utilization:.1f}%
- å†…å­˜å›æ”¶æ•ˆç‡: {metrics.memory_reclaim_efficiency:.1f}%

"""
    
    if "all" in metric_types or "trends" in metric_types:
        report += f"""### ğŸ“ˆ è¶‹åŠ¿åˆ†æ
- åœé¡¿æ—¶é—´è¶‹åŠ¿: {metrics.pause_time_trend}
- å†…å­˜ä½¿ç”¨è¶‹åŠ¿: {metrics.memory_usage_trend}

"""
    
    if "all" in metric_types or "health" in metric_types:
        report += f"""### ğŸ¯ å¥åº·è¯„ä¼°
- æ€§èƒ½è¯„åˆ†: {metrics.performance_score:.1f}/100
- å¥åº·çŠ¶æ€: {metrics.health_status}
"""
    
    return report.strip()


def generate_comparison_report(result1: Dict, result2: Dict) -> str:
    """ç”Ÿæˆæ¯”è¾ƒæŠ¥å‘Š"""
    metrics1 = result1.get('metrics')
    metrics2 = result2.get('metrics')
    
    if not metrics1 or not metrics2:
        return "âŒ æ— æ³•æ¯”è¾ƒï¼šç¼ºå°‘æ€§èƒ½æŒ‡æ ‡æ•°æ®"
    
    # è®¡ç®—å·®å¼‚
    throughput_diff = metrics2.throughput_percentage - metrics1.throughput_percentage
    latency_diff = metrics2.avg_pause_time - metrics1.avg_pause_time
    score_diff = metrics2.performance_score - metrics1.performance_score
    
    report = f"""## ğŸ“Š GCæ—¥å¿—å¯¹æ¯”åˆ†æ

### æ–‡ä»¶ä¿¡æ¯
- **æ–‡ä»¶1**: {result1['file_path']} ({result1['log_type']})
- **æ–‡ä»¶2**: {result2['file_path']} ({result2['log_type']})

### å…³é”®æŒ‡æ ‡å¯¹æ¯”

| æŒ‡æ ‡ | æ–‡ä»¶1 | æ–‡ä»¶2 | å·®å¼‚ |
|------|-------|-------|------|
| æ€§èƒ½è¯„åˆ† | {metrics1.performance_score:.1f} | {metrics2.performance_score:.1f} | {score_diff:+.1f} |
| ååé‡ | {metrics1.throughput_percentage:.1f}% | {metrics2.throughput_percentage:.1f}% | {throughput_diff:+.1f}% |
| å¹³å‡åœé¡¿ | {metrics1.avg_pause_time:.1f}ms | {metrics2.avg_pause_time:.1f}ms | {latency_diff:+.1f}ms |
| P95åœé¡¿ | {metrics1.p95_pause_time:.1f}ms | {metrics2.p95_pause_time:.1f}ms | {metrics2.p95_pause_time - metrics1.p95_pause_time:+.1f}ms |
| GCé¢‘ç‡ | {metrics1.gc_frequency:.2f}/s | {metrics2.gc_frequency:.2f}/s | {metrics2.gc_frequency - metrics1.gc_frequency:+.2f}/s |

### ğŸ“ˆ åˆ†æç»“è®º
"""
    
    if score_diff > 5:
        report += "âœ… æ–‡ä»¶2çš„æ€§èƒ½æ˜æ˜¾ä¼˜äºæ–‡ä»¶1\n"
    elif score_diff < -5:
        report += "âŒ æ–‡ä»¶2çš„æ€§èƒ½æ˜æ˜¾åŠ£äºæ–‡ä»¶1\n"
    else:
        report += "â– ä¸¤ä¸ªæ–‡ä»¶çš„æ€§èƒ½å·®å¼‚ä¸å¤§\n"
    
    if throughput_diff > 1:
        report += f"ğŸ“ˆ æ–‡ä»¶2çš„ååé‡æå‡äº†{throughput_diff:.1f}%\n"
    elif throughput_diff < -1:
        report += f"ğŸ“‰ æ–‡ä»¶2çš„ååé‡ä¸‹é™äº†{abs(throughput_diff):.1f}%\n"
    
    if latency_diff < -10:
        report += f"âš¡ æ–‡ä»¶2çš„åœé¡¿æ—¶é—´å‡å°‘äº†{abs(latency_diff):.1f}ms\n"
    elif latency_diff > 10:
        report += f"ğŸŒ æ–‡ä»¶2çš„åœé¡¿æ—¶é—´å¢åŠ äº†{latency_diff:.1f}ms\n"
    
    return report


def generate_issues_report(metrics: Any, threshold_config: Dict) -> str:
    """ç”Ÿæˆé—®é¢˜æ£€æµ‹æŠ¥å‘Š"""
    max_pause_time = threshold_config.get("max_pause_time", 100)
    min_throughput = threshold_config.get("min_throughput", 95)
    
    issues = []
    recommendations = []
    
    # æ£€æµ‹åœé¡¿æ—¶é—´é—®é¢˜
    if metrics.max_pause_time > max_pause_time:
        issues.append(f"âš ï¸ æœ€å¤§åœé¡¿æ—¶é—´è¿‡é•¿: {metrics.max_pause_time:.1f}ms (é˜ˆå€¼: {max_pause_time}ms)")
        recommendations.append("è€ƒè™‘è°ƒæ•´GCå‚æ•°å‡å°‘åœé¡¿æ—¶é—´")
    
    if metrics.p99_pause_time > max_pause_time * 0.8:
        issues.append(f"âš ï¸ P99åœé¡¿æ—¶é—´è¾ƒé«˜: {metrics.p99_pause_time:.1f}ms")
        recommendations.append("æ£€æŸ¥æ˜¯å¦æœ‰å†…å­˜åˆ†é…å³°å€¼")
    
    # æ£€æµ‹ååé‡é—®é¢˜
    if metrics.throughput_percentage < min_throughput:
        issues.append(f"âš ï¸ ååé‡è¿‡ä½: {metrics.throughput_percentage:.1f}% (é˜ˆå€¼: {min_throughput}%)")
        recommendations.append("è€ƒè™‘ä¼˜åŒ–GCç­–ç•¥ä»¥æé«˜ååé‡")
    
    # æ£€æµ‹GCé¢‘ç‡é—®é¢˜
    if metrics.gc_frequency > 10:
        issues.append(f"âš ï¸ GCé¢‘ç‡è¿‡é«˜: {metrics.gc_frequency:.1f} æ¬¡/ç§’")
        recommendations.append("æ£€æŸ¥æ˜¯å¦å­˜åœ¨å†…å­˜æ³„æ¼æˆ–åˆ†é…è¿‡äºé¢‘ç¹")
    
    if metrics.full_gc_frequency > 0.1:
        issues.append(f"âš ï¸ Full GCé¢‘ç‡è¾ƒé«˜: {metrics.full_gc_frequency:.2f} æ¬¡/ç§’")
        recommendations.append("Full GCé¢‘ç¹å¯èƒ½è¡¨ç¤ºå †å¤§å°ä¸è¶³æˆ–å­˜åœ¨å†…å­˜æ³„æ¼")
    
    # æ£€æµ‹è¶‹åŠ¿é—®é¢˜
    if metrics.pause_time_trend == "increasing":
        issues.append("ğŸ“ˆ åœé¡¿æ—¶é—´å‘ˆä¸Šå‡è¶‹åŠ¿")
        recommendations.append("ç›‘æ§å†…å­˜ä½¿ç”¨æƒ…å†µï¼Œå¯èƒ½éœ€è¦è°ƒæ•´å †å¤§å°")
    
    if metrics.memory_usage_trend == "increasing":
        issues.append("ğŸ“ˆ å†…å­˜ä½¿ç”¨å‘ˆä¸Šå‡è¶‹åŠ¿")
        recommendations.append("æ£€æŸ¥æ˜¯å¦å­˜åœ¨å†…å­˜æ³„æ¼")
    
    # ç”ŸæˆæŠ¥å‘Š
    report = f"""## ğŸ” GCæ€§èƒ½é—®é¢˜æ£€æµ‹æŠ¥å‘Š

### å½“å‰çŠ¶æ€
- **å¥åº·çŠ¶æ€**: {metrics.health_status}
- **æ€§èƒ½è¯„åˆ†**: {metrics.performance_score:.1f}/100

"""
    
    if issues:
        report += "### âš ï¸ å‘ç°çš„é—®é¢˜\n"
        for issue in issues:
            report += f"- {issue}\n"
        report += "\n"
    else:
        report += "### âœ… æœªå‘ç°æ˜æ˜¾æ€§èƒ½é—®é¢˜\n\n"
    
    if recommendations:
        report += "### ğŸ’¡ ä¼˜åŒ–å»ºè®®\n"
        for rec in recommendations:
            report += f"- {rec}\n"
        report += "\n"
    
    # æ·»åŠ è¯¦ç»†æŒ‡æ ‡
    report += f"""### ğŸ“Š è¯¦ç»†æŒ‡æ ‡
- **ååé‡**: {metrics.throughput_percentage:.1f}%
- **å¹³å‡åœé¡¿**: {metrics.avg_pause_time:.1f}ms
- **P99åœé¡¿**: {metrics.p99_pause_time:.1f}ms
- **GCé¢‘ç‡**: {metrics.gc_frequency:.2f} æ¬¡/ç§’
- **å†…å­˜å›æ”¶æ•ˆç‡**: {metrics.memory_reclaim_efficiency:.1f}%
"""
    
    return report


async def main():
    """
    MCPæœåŠ¡å™¨ä¸»å‡½æ•°
    """
    logger.info("ğŸš€ å¯åŠ¨GCæ—¥å¿—åˆ†æMCPæœåŠ¡å™¨...")
    
    # ä½¿ç”¨stdioä¼ è¾“è¿è¡ŒæœåŠ¡å™¨
    async with stdio_server() as (read_stream, write_stream):
        await app.run(
            read_stream,
            write_stream,
            app.create_initialization_options()
        )


if __name__ == "__main__":
    asyncio.run(main())